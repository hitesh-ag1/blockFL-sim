{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55b9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import math\n",
    "from data_partition_2 import DistributedDataSet\n",
    "from init_ipfs_nodes import create_ipfs_nodes\n",
    "import ipfshttpclient\n",
    "import piskg\n",
    "import copy\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import time\n",
    "from web3 import Web3, HTTPProvider\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4285e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS = 8 #don't set more than 9 because of IPFS initialization script\n",
    "CLIENT_GRAPH = {\n",
    "    0: [1, 4],\n",
    "    1: [0, 5, 2],\n",
    "    2: [3, 1],\n",
    "    3: [2, 4, 6],\n",
    "    4: [3, 7, 0],\n",
    "    5: [1],\n",
    "    6: [3],\n",
    "    7: [4]\n",
    "}\n",
    "\n",
    "# CLIENTS = 4 #don't set more than 9 because of IPFS initialization script\n",
    "# CLIENT_GRAPH = {\n",
    "#     0: [1, 2],\n",
    "#     1: [0, 3],\n",
    "#     2: [0, 3],\n",
    "#     3: [1, 2],\n",
    "# }\n",
    "\n",
    "SEED = 0\n",
    "ROUNDS = 5\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "#supports only pandas dataframe for now. \n",
    "#input values should be labelled as x0, x1, etc. \n",
    "#output values should be labelled as y\n",
    "DATASET = pd.read_csv(\"dataset/train.csv\")\n",
    "\n",
    "\n",
    "server = Web3(HTTPProvider('http://localhost:8545'))\n",
    "CONTRACT_ADDRESS = server.toChecksumAddress(\"0xb40D7aA2e717C1Ac62F65a96EcD0019e9B527847\")\n",
    "DEFAULT_ADDRESS  = server.toChecksumAddress(server.eth.accounts[0])\n",
    "with open('../blkTrial/HelloWorld/build/contracts/Model.json') as f:\n",
    "    CONTRACT_DATA = json.load(f)\n",
    "CONTRACT_ABI = CONTRACT_DATA['abi']\n",
    "BLKCHAIN_ACCOUNTS = server.eth.accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51aac34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DistributedDataSet(DATASET, SEED, CLIENTS)\n",
    "df_di, test = dd.get_distributed_dataset(0.1, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45253d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl0\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWPT6sTY5sDgh4UgxNU2v6rys5hQWLjtEnGdQ7wMc4fedC\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl1\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWLp1KsrLemBJw82rE3nx9hNURNKRFAc43JYRYVTSqkEaG\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl2\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWT1MXqm5TzyESmnh1TLvkL3LN1mE6X7iNUmzr1rS3Tf3w\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl3\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWFjD3UzzdUtNBATbov471ft2HL3GczeHhbE4zL2dYxC4H\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl4\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWJntmfqKCCMPaWHjUiq4L375D4dvMWGyQMZrRhqCk2LCb\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl5\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWFwWGdohc2RyAPBSJdqw3CQj4Cu6CdTF7BaAfm3waDSjd\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl6\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "generating ED25519 keypair...done\n",
      "peer identity: 12D3KooWMhSTQwZbYecmZYnqexfBKYHoTgwcjMyeEM4xU84JGbv1\n",
      "initializing IPFS node at /home/hitesh/.ipfs_fl7\n",
      "to get started, enter:\n",
      "\n",
      "\tipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme\n",
      "\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb\n",
      "removed /dnsaddr/bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt\n",
      "removed /ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "removed /ip4/104.131.131.82/udp/4001/quic/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "added /ip4/172.31.46.83/tcp/4002/ipfs/12D3KooWMJf8s3j1vym148NdTxrHoFZXBwuKNc89kSbToj68ZrKG\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4004\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4004\n",
      "Swarm listening on /ip6/::1/tcp/4004\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4004\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4004\n",
      "Swarm announcing /ip6/::1/tcp/4004\n",
      "API server listening on /ip4/127.0.0.1/tcp/5004\n",
      "WebUI: http://127.0.0.1:5004/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8083\n",
      "Daemon is ready\n",
      "Initializing daemon...\n",
      "go-ipfs version: 0.11.0\n",
      "Repo version: 11\n",
      "System version: amd64/linux\n",
      "Golang version: go1.16.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4002\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4002\n",
      "Swarm listening on /ip6/::1/tcp/4002\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4002\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4002\n",
      "Swarm announcing /ip6/::1/tcp/4002\n",
      "API server listening on /ip4/127.0.0.1/tcp/5002\n",
      "WebUI: http://127.0.0.1:5002/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8081\n",
      "Daemon is ready\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4003\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4003\n",
      "Swarm listening on /ip6/::1/tcp/4003\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4003\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4003\n",
      "Swarm announcing /ip6/::1/tcp/4003\n",
      "API server listening on /ip4/127.0.0.1/tcp/5003\n",
      "WebUI: http://127.0.0.1:5003/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8082\n",
      "Daemon is ready\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4005\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4005\n",
      "Swarm listening on /ip6/::1/tcp/4005\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4005\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4005\n",
      "Swarm announcing /ip6/::1/tcp/4005\n",
      "API server listening on /ip4/127.0.0.1/tcp/5005\n",
      "WebUI: http://127.0.0.1:5005/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8084\n",
      "Daemon is ready\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4007\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4007\n",
      "Swarm listening on /ip6/::1/tcp/4007\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4007\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4007\n",
      "Swarm announcing /ip6/::1/tcp/4007\n",
      "API server listening on /ip4/127.0.0.1/tcp/5007\n",
      "WebUI: http://127.0.0.1:5007/webui\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4006\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4006\n",
      "Swarm listening on /ip6/::1/tcp/4006\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4006\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4006\n",
      "Swarm announcing /ip6/::1/tcp/4006\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8086\n",
      "Daemon is ready\n",
      "API server listening on /ip4/127.0.0.1/tcp/5006\n",
      "WebUI: http://127.0.0.1:5006/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8085\n",
      "Daemon is ready\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4009\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4009\n",
      "Swarm listening on /ip6/::1/tcp/4009\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm is limited to private network of peers with the swarm key\n",
      "Swarm key fingerprint: 9a4fbdf299037058da0d21a048cd93c8\n",
      "Swarm listening on /ip4/127.0.0.1/tcp/4008\n",
      "Swarm listening on /ip4/172.31.46.83/tcp/4008\n",
      "Swarm listening on /ip6/::1/tcp/4008\n",
      "Swarm listening on /p2p-circuit\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4008\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4008\n",
      "Swarm announcing /ip6/::1/tcp/4008\n",
      "API server listening on /ip4/127.0.0.1/tcp/5008\n",
      "WebUI: http://127.0.0.1:5008/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8087\n",
      "Daemon is ready\n",
      "Swarm announcing /ip4/127.0.0.1/tcp/4009\n",
      "Swarm announcing /ip4/172.31.46.83/tcp/4009\n",
      "Swarm announcing /ip6/::1/tcp/4009\n",
      "API server listening on /ip4/127.0.0.1/tcp/5009\n",
      "WebUI: http://127.0.0.1:5009/webui\n",
      "Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8088\n",
      "Daemon is ready\n"
     ]
    }
   ],
   "source": [
    "create_ipfs_nodes(CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df7dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClientNetwork:\n",
    "#     def __init__(self, count, structure, ipfs, blkchain, train_data, test_data):\n",
    "#         self.count = count\n",
    "#         self.structure = structure\n",
    "#         self.clients = ipfs\n",
    "#         self.blkchain = blkchain\n",
    "#         self.train_data = train_data\n",
    "#         self.test_data = test_data\n",
    "        \n",
    "#         self.clients = []\n",
    "        \n",
    "#     def start_clients(self):\n",
    "#         for i in range(self.count):\n",
    "#             ag = Client(i, self.structure[i], sekf.train_data[i], self.ipfs, self.blkchain, self.test)\n",
    "#             self.clients.append(ag)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46515a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default(obj):\n",
    "    if type(obj).__module__ == np.__name__:\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return obj.item()\n",
    "    else:\n",
    "        return obj.total_seconds()\n",
    "#     raise TypeError('Unknown type:', type(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab40751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTime(messages):\n",
    "    simulated_communication_times = {i: messages[i]['time'] for i in range(len(messages))}\n",
    "    slowest_client = max(simulated_communication_times, key=simulated_communication_times.get)\n",
    "    simulated_time = simulated_communication_times[slowest_client]  # simulated time it would take for server to receive all values\n",
    "    return simulated_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37688e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message:\n",
    "    def __init__(self, sender, receiver, body):\n",
    "        self.sender = sender\n",
    "        self.receiver = receiver\n",
    "        self.body = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a660ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, neighbour_ids, client_datasets, client_ipfs_node, client_blkchain_node, test_dataset):\n",
    "        \n",
    "        self.client_id = client_id\n",
    "        self.neighbour_ids = neighbour_ids\n",
    "        self.neighbour_ids.append(self.client_id) #neighbour includes itself\n",
    "        self.client_datasets = client_datasets\n",
    "        self.client_ipfs_node = client_ipfs_node\n",
    "        self.client_blkchain_node = client_blkchain_node\n",
    "        self.test_dataset = test_dataset\n",
    "        \n",
    "        self.personal_weights = {}        \n",
    "        self.federated_weights = {}\n",
    "        \n",
    "        self.personal_accuracy = {}\n",
    "        self.federated_accuracy = {}\n",
    "        \n",
    "        self.train_time = {}\n",
    "        \n",
    "        self.nb_weights = {}\n",
    "        \n",
    "        self.ipfsHash = {}\n",
    "        \n",
    "        self.nb_hash = {}\n",
    "        \n",
    "        self.blkchain_update = {}\n",
    "    \n",
    "    def addModelIpfs(self, round_it):\n",
    "        start_time = datetime.now()\n",
    "        model = {\n",
    "                 'weights': self.personal_weights[round_it],\n",
    "                 'time': self.train_time[round_it]\n",
    "                }\n",
    "        with open('model'+str(self.client_id)+'.json', 'w') as f:\n",
    "            json.dump(model, f, default=default)\n",
    "\n",
    "        cmd = \"IPFS_PATH=~/\"+self.client_ipfs_node+\" ipfs add model\"+str(self.client_id)+\".json\"\n",
    "        \n",
    "        try:\n",
    "            modelHash = (os.popen(cmd).read()).strip()\n",
    "            modelHash = modelHash.split()[1]\n",
    "            self.ipfsHash[round_it] = modelHash\n",
    "            stop_time = datetime.now()\n",
    "            ipfs_time = (stop_time - start_time)\n",
    "            return modelHash\n",
    "        except:\n",
    "            stop_time = datetime.now()\n",
    "            ipfs_time = (stop_time - start_time)\n",
    "            return 0\n",
    "        \n",
    "    def recModelIpfs(self, round_it, ipfs_hash):\n",
    "            cmd = \"IPFS_PATH=~/\"+self.client_ipfs_node+\" ipfs cat \"+ipfs_hash\n",
    "            model = (os.popen(cmd).read()).strip()\n",
    "            start_time = datetime.now()\n",
    "            model = json.loads(os.popen(cmd).read())\n",
    "            stop_time = datetime.now()\n",
    "            ipfs_time = (stop_time - start_time)\n",
    "            return model\n",
    "        \n",
    "    def modelChecker(self, round_it):\n",
    "        try:\n",
    "            a = self.ipfsHash[round_it]\n",
    "            return None\n",
    "        except KeyError:\n",
    "            return self.client_id\n",
    "    \n",
    "    def client_modelCheck_caller(self, deets):\n",
    "        client_instance, msg = deets\n",
    "        round_it = msg.body['round']\n",
    "        m = client_instance.modelChecker(round_it)\n",
    "        return m\n",
    "    \n",
    "\n",
    "    def get_ipfs_hash(self, target_node_blk, round_it, target_node_id):\n",
    "        contract = server.eth.contract(address=CONTRACT_ADDRESS, abi=CONTRACT_ABI)\n",
    "        msg = contract.functions.getIpfsHashForUser(target_node_blk, str(round_it)).call()\n",
    "        if(msg==''):\n",
    "            print(\"Round \"+str(round_it)+\" missing on blockchain for Node \"+str(target_node_id))\n",
    "            return 0\n",
    "        else:\n",
    "            return (msg)\n",
    "            \n",
    "\n",
    "    def client_model_caller(self, deets):\n",
    "        client_instance, msg = deets\n",
    "        round_it = msg.body['round']\n",
    "        target_node_blk = client_instance.client_blkchain_node\n",
    "        target_node_id = client_instance.client_id\n",
    "        ipfs_hash = self.get_ipfs_hash(target_node_blk, round_it, target_node_id)\n",
    "        if(ipfs_hash!=0):\n",
    "            m = self.recModelIpfs(round_it, ipfs_hash)\n",
    "            return m\n",
    "        else:\n",
    "            print(\"Couldn't retreive ipfs hash from blockchain.\")\n",
    "    \n",
    "    def client_train_caller(self, deets):\n",
    "        client_instance, msg = deets\n",
    "#         print(\"Training Caller: \", client_instance.client_id)\n",
    "        if(client_instance.client_id == self.client_id):\n",
    "            self.train_client(msg)\n",
    "        else:  \n",
    "            client_instance.train_client(msg)\n",
    "#         print(\"Training Caller 2: \", client_instance.client_id)\n",
    "    \n",
    "    \n",
    "    def network_train_caller(self, numRounds):\n",
    "        for num in range(numRounds):\n",
    "            print(\"Training round: \", num)\n",
    "            self.get_nb_weights(num)\n",
    "            time.sleep(5)\n",
    "            print(\"Validation accuracy: \", self.personal_accuracy[num])\n",
    "            print()\n",
    "    \n",
    "    def get_nb_weights(self, round_it):\n",
    "        m = multiprocessing.Manager()\n",
    "        lock = m.Lock()\n",
    "        \n",
    "        with ThreadPool(len(self.neighbour_ids)) as calling_pool:\n",
    "            args = []\n",
    "            for cl in (self.neighbour_ids):\n",
    "                body = {'round': round_it, 'lock': lock}\n",
    "                msg = Message(self.client_id, cl, body)\n",
    "                args.append((allCl.clients[cl], msg))\n",
    "            msgs = calling_pool.map(self.client_modelCheck_caller, args)\n",
    "            msgs = np.array(msgs)\n",
    "        \n",
    "        untrained_nb = list(msgs[msgs!=None])\n",
    "        print(\"Current Node: \", self.client_id)\n",
    "        print(\"Untrained Neighbour: \", untrained_nb)\n",
    "        print(\"All neighbours: \", self.neighbour_ids)\n",
    "        if(len(untrained_nb)!=0):\n",
    "            with ThreadPool(len(untrained_nb)) as calling_pool:\n",
    "                args = []\n",
    "                for cl in (untrained_nb):\n",
    "                    body = {'round': round_it, 'lock': lock}\n",
    "                    msg = Message(self.client_id, cl, body)\n",
    "                    args.append((allCl.clients[cl], msg))\n",
    "                calling_pool.map(self.client_train_caller, args)\n",
    "                \n",
    "        with ThreadPool(len(self.neighbour_ids)) as calling_pool:\n",
    "            args = []\n",
    "            for cl in (self.neighbour_ids):\n",
    "                body = {'round': round_it, 'lock': lock}\n",
    "                msg = Message(self.client_id, cl, body)\n",
    "                args.append((allCl.clients[cl], msg))\n",
    "            msgs = calling_pool.map(self.client_model_caller, args)        \n",
    "        \n",
    "        time_start = datetime.now()\n",
    "        train_time = getTime(msgs)\n",
    "        \n",
    "        self.nb_weights[round_it] = []\n",
    "        \n",
    "        for msg in msgs:\n",
    "            self.nb_weights[round_it].append(msg['weights'])\n",
    "        \n",
    "        time_stop = datetime.now()\n",
    "        fedtime = time_stop - time_start\n",
    "        totTime = fedtime+timedelta(train_time)\n",
    "        self.FedAvg(round_it)\n",
    "    \n",
    "    def FedAvg(self, round_it):\n",
    "        \n",
    "        new_weights = list()\n",
    "        for weights_list_tuple in zip(*self.nb_weights[round_it]):\n",
    "            new_weights.append([np.array(weights_).mean(axis=0) for weights_ in zip(*weights_list_tuple)])\n",
    "        \n",
    "        self.federated_weights[round_it] = new_weights\n",
    "\n",
    "        \n",
    "    def data_preprocessing(self, X, y):\n",
    "        from keras.utils.np_utils import to_categorical\n",
    "        X = X/255.0\n",
    "        y = to_categorical(y, num_classes=10)\n",
    "        X = X.values.reshape(-1, 28, 28, 1)\n",
    "        return (X, y)\n",
    "    \n",
    "    def NN(self):\n",
    "        \n",
    "        import tensorflow as tf\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "        from tensorflow.keras.optimizers import RMSprop\n",
    "        from keras.preprocessing.image import ImageDataGenerator\n",
    "        from keras.callbacks import ReduceLROnPlateau\n",
    "        \n",
    "        tf.config.run_functions_eagerly(True)\n",
    "        tf.data.experimental.enable_debug_mode()\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                         activation ='relu', input_shape = (28,28,1)))\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                         activation ='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                         activation ='relu'))\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                         activation ='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation = \"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation = \"softmax\"))\n",
    "        \n",
    "        optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "        model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"], run_eagerly=True)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    \n",
    "    def train_client(self, message):\n",
    "            training_flag = 0\n",
    "            blkchain_upload = 0\n",
    "            print(\"Training node \", self.client_id)\n",
    "            round_it = message.body['round']\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            X = self.client_datasets.drop('y', axis=1)\n",
    "            y = self.client_datasets['y']\n",
    "            X, y = self.data_preprocessing(X, y)\n",
    "    \n",
    "            if(training_flag == 0):\n",
    "                weights = self.compute_epoch(X, y, round_it, message.sender, self.client_id)\n",
    "                try:\n",
    "                    self.personal_weights[round_it]\n",
    "                    training_flag = 1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            if(training_flag == 0):\n",
    "                self.personal_weights[round_it] = weights\n",
    "                stop_time = datetime.now()\n",
    "                comp_time = stop_time - start_time\n",
    "                self.train_time[round_it] = comp_time\n",
    "                success = self.addModelIpfs(round_it)\n",
    "                print(\"Training finished for \", self.client_id)\n",
    "                if (success!=0):\n",
    "                    contract = server.eth.contract(address=CONTRACT_ADDRESS, abi=CONTRACT_ABI)\n",
    "                    tx_hash = contract.functions.addFile(str(round_it), success).transact({'from':self.client_blkchain_node})\n",
    "                    rec = server.eth.waitForTransactionReceipt(tx_hash)\n",
    "                    if(rec['status']!=1):\n",
    "                        print('TRANSACTION REVERTED BY BLOCKCHAIN')\n",
    "                    else:\n",
    "                        self.blkchain_update[round_it] = 1\n",
    "            else:\n",
    "                while(blkchain_upload==0):\n",
    "                    try:\n",
    "                        self.blkchain_update[round_it]\n",
    "                        blkchain_upload = 1\n",
    "#                         print(\"Training over\")\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                print(\"Client \", self.client_id, \" trained already.\")\n",
    "            \n",
    "            \n",
    "                    \n",
    "    \n",
    "    def compute_epoch(self, X, y, round_it, sender, receiver):            \n",
    "        model = self.NN()\n",
    "        if(round_it>=1):\n",
    "            try:\n",
    "                weights = copy.deepcopy(self.federated_weights[round_it - 1])\n",
    "                print(\"Federated weights set for epoch \", epoch, \" in round  \", round_it)\n",
    "                \n",
    "            except: \n",
    "                rounds_trained = len(self.nb_weights)\n",
    "                while(rounds_trained<round_it):\n",
    "                    self.get_nb_weights(rounds_trained)\n",
    "                    rounds_trained+=1\n",
    "\n",
    "                try:\n",
    "                    weights = copy.deepcopy(self.federated_weights[round_it - 1])\n",
    "                except:\n",
    "#                         print(\"Round: \", round_it)\n",
    "#                         print(\"Node: \", self.client_id)\n",
    "#                         print(\"Maxi var: \", maxi)\n",
    "                    weights = copy.deepcopy(self.federated_weights[round_it - 1])\n",
    "        else:\n",
    "            weights = None\n",
    "                \n",
    "        if(weights!=None):\n",
    "            for layeri in range(len(model.layers)):\n",
    "                (model.layers[layeri]).set_weights(weights[layeri])\n",
    "#         print(X.shape)\n",
    "#         print(y.shape)\n",
    "        model.fit(X, y, verbose=0, batch_size = BATCH_SIZE ,epochs=5)\n",
    "        local_weights = [layer.get_weights() for layer in model.layers]\n",
    "\n",
    "        X = self.test_dataset.drop('y', axis=1)\n",
    "        y = self.test_dataset['y']\n",
    "        X, y = self.data_preprocessing(X, y)\n",
    "\n",
    "        acc = model.evaluate(X, y, batch_size=BATCH_SIZE, verbose=0, return_dict=True)\n",
    "        self.personal_accuracy[round_it] = acc['accuracy']\n",
    "            \n",
    "        return local_weights\n",
    "        \n",
    "#     def federated_averaging(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4dce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllClients:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        self.training = {int(client): False for client in range(CLIENTS)}\n",
    "        with open('training.json', 'w') as f:\n",
    "            json.dump(self.training, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12d2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_li = []\n",
    "for i in range(CLIENTS):\n",
    "    ag = Client(i, CLIENT_GRAPH[i], df_di[i], '.ipfs_fl'+str(i), BLKCHAIN_ACCOUNTS[i], test)\n",
    "    client_li.append(ag)\n",
    "\n",
    "allCl = AllClients(client_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d15726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round:  0\n",
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  4\n",
      "Training node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 22:07:51.916253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:52.007460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:52.008723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:52.009466: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-01 22:07:52.012068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:52.013027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:52.013956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:53.168190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:53.168947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:53.168968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-01 22:07:53.169574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 22:07:53.169874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3929 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-03-01 22:07:55.502730: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8301\n",
      " 1.25 MiB / 18.77 MiB    6.66%0%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n",
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 9.32 MiB / 18.77 MiB   49.68%\u001b[2KK\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.9630952477455139\n",
      "\n",
      "Training round:  1\n",
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  Training node  1\n",
      "4\n",
      "Training node  0\n",
      "Current Node:  1\n",
      "Untrained Neighbour:  [5, 2]\n",
      "All neighbours:  [0, 5, 2, 1]\n",
      "Training node  5\n",
      "Training node  2\n",
      "Current Node:  4\n",
      "Untrained Neighbour:  [3, 7]\n",
      "All neighbours:  [3, 7, 0, 4]\n",
      "Training node  3\n",
      "Training node  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2KK"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n",
      "Training finished for  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 5.00 MiB / 18.77 MiB   26.64%\u001b[2KK\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.98 MiB / 18.98 MiB  100.00%%[2K1ss\u001b[2K\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.98 MiB / 18.98 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2.54 MiB / 18.98 MiB   13.38% 00m01s\u001b[2K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.9580952525138855\n",
      "\n",
      "Training round:  2\n",
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  4\n",
      "Training node  0\n",
      "Current Node:  4\n",
      "Untrained Neighbour:  [3, 7]\n",
      "All neighbours:  [3, 7, 0, 4]\n",
      "Training node  3\n",
      "Training node  7\n",
      "Current Node:  1\n",
      "Untrained Neighbour:  [5, 2]\n",
      "All neighbours:  [0, 5, 2, 1]\n",
      "Training node  5Training node  2\n",
      "\n",
      "Current Node:  3\n",
      "Untrained Neighbour:  [6]\n",
      "All neighbours:  [2, 4, 6, 3]\n",
      "Training node  6\n",
      "Current Node:  5\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [1, 5]\n",
      "Current Node:  2\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [3, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 0 B / 18.77 MiB    0.00%2.87% 00m02s8s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  7\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [4, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.97 MiB / 18.97 MiB  100.00%\u001b[2K01s\u001b[2K[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.87 MiB / 18.87 MiB  100.00%%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3.00 MiB / 18.77 MiB   15.98%%\u001b[2K01ss"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3.00 MiB / 18.77 MiB   15.98%%%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.97 MiB / 18.97 MiB  100.00%\u001b[2K2ss"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3.00 MiB / 18.77 MiB   15.98%Error: canceled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n",
      "\n",
      "Received interrupt signal, shutting down...\n",
      "(Hit ctrl-c again to force-shutdown the daemon.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2.16 MiB / 18.77 MiB   11.49%Error: failed to fetch all nodes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mallCl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_train_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mClient.network_train_caller\u001b[0;34m(self, numRounds)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numRounds):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining round: \u001b[39m\u001b[38;5;124m\"\u001b[39m, num)\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nb_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersonal_accuracy[num])\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mClient.get_nb_weights\u001b[0;34m(self, round_it)\u001b[0m\n\u001b[1;32m    136\u001b[0m             msg \u001b[38;5;241m=\u001b[39m Message(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_id, cl, body)\n\u001b[1;32m    137\u001b[0m             args\u001b[38;5;241m.\u001b[39mappend((allCl\u001b[38;5;241m.\u001b[39mclients[cl], msg))\n\u001b[0;32m--> 138\u001b[0m         \u001b[43mcalling_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_train_caller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPool(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighbour_ids)) \u001b[38;5;28;01mas\u001b[39;00m calling_pool:\n\u001b[1;32m    141\u001b[0m     args \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allCl.clients[0].network_train_caller(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8524e85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  4\n",
      "Training node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:51:23.700400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:23.817551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:23.818515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:23.821693: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-01 21:51:23.825133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:23.826190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:23.827175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:25.318333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:25.319256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:25.319278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-01 21:51:25.320086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-01 21:51:25.320517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3929 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-03-01 21:51:27.940664: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8301\n",
      " 18.77 MiB / 18.77 MiB  100.00%[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n",
      "Training finished for  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.38 MiB / 18.77 MiB   97.94%\u001b[2K40s\u001b[2K\r"
     ]
    }
   ],
   "source": [
    "allCl.clients[0].get_nb_weights(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61860dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9611904621124268} {0: 0.9395238161087036} {} {}\n"
     ]
    }
   ],
   "source": [
    "print(allCl.clients[0].personal_accuracy, allCl.clients[1].personal_accuracy, allCl.clients[2].personal_accuracy, allCl.clients[3].personal_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5206c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  4\n",
      "Training node  0\n",
      "Current Node:  4\n",
      "Untrained Neighbour:  [3, 7]\n",
      "All neighbours:  [3, 7, 0, 4]\n",
      "Training node  3\n",
      "Training node  7\n",
      "Current Node:  1\n",
      "Untrained Neighbour:  [5, 2]\n",
      "All neighbours:  [0, 5, 2, 1]\n",
      "Training node  5\n",
      "Training node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.94 MiB / 18.94 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11.03 MiB / 18.77 MiB   58.77%\u001b[2K4s\u001b[2K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.97 MiB / 18.97 MiB  100.00%%[2K1s\u001b[2KK\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.98 MiB / 18.98 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3.59 MiB / 18.98 MiB   18.93%\u001b[2KK\r"
     ]
    }
   ],
   "source": [
    "allCl.clients[0].get_nb_weights(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a624cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9611904621124268, 1: 0.9576190710067749} {0: 0.9395238161087036, 1: 0.9547619223594666} {0: 0.9616666436195374} {0: 0.9578571319580078}\n"
     ]
    }
   ],
   "source": [
    "print(allCl.clients[0].personal_accuracy, allCl.clients[1].personal_accuracy, allCl.clients[2].personal_accuracy, allCl.clients[3].personal_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf246ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  4\n",
      "Training node  0\n",
      "Current Node:  4\n",
      "Untrained Neighbour:  [3, 7]\n",
      "All neighbours:  [3, 7, 0, 4]\n",
      "Training node  3\n",
      "Training node  7\n",
      "Current Node:  1\n",
      "Untrained Neighbour:  [5, 2]\n",
      "All neighbours:  [0, 5, 2, 1]\n",
      "Training node  5\n",
      "Training node  2\n",
      "Current Node:  3\n",
      "Untrained Neighbour:  [6]\n",
      "All neighbours:  [2, 4, 6, 3]\n",
      "Training node  6\n",
      "Current Node:  5\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [1, 5]\n",
      "Current Node: Current Node:  7\n",
      "Untrained Neighbour:  2\n",
      " []\n",
      "Untrained Neighbour:  All neighbours:  []\n",
      "All neighbours: [4, 7]\n",
      " [3, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.97 MiB / 18.97 MiB  100.00%\u001b[2K01s[2K\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.87 MiB / 18.87 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.87 MiB / 18.87 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.77 MiB / 18.77 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10.83 MiB / 18.77 MiB   57.72%\u001b[2K1s\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.98 MiB / 18.98 MiB  100.00%%[2K39ss\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.95 MiB / 18.95 MiB  100.00%\u001b[2K1s\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.97 MiB / 18.97 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K00 KiB / 18.97 MiB    0.45% 00m43s\u001b[2K\r"
     ]
    }
   ],
   "source": [
    "allCl.clients[0].get_nb_weights(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26220bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9611904621124268, 1: 0.9576190710067749, 2: 0.9435714483261108} {0: 0.9395238161087036, 1: 0.9547619223594666, 2: 0.9680952429771423} {0: 0.9616666436195374, 1: 0.9595237970352173} {0: 0.9578571319580078, 1: 0.9490476250648499}\n"
     ]
    }
   ],
   "source": [
    "print(allCl.clients[0].personal_accuracy, allCl.clients[1].personal_accuracy, allCl.clients[2].personal_accuracy, allCl.clients[3].personal_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35757151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  4\n",
      "Training node  0\n",
      "Current Node:  1\n",
      "Untrained Neighbour:  [5, 2]\n",
      "All neighbours:  [0, 5, 2, 1]\n",
      "Training node  5\n",
      "Training node  2\n",
      "Current Node:  4\n",
      "Untrained Neighbour:  [3, 7]\n",
      "All neighbours:  [3, 7, 0, 4]\n",
      "Training node  Training node  7\n",
      "3\n",
      "Current Node:  5\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [1, 5]\n",
      "Current Node:  3\n",
      "Untrained Neighbour:  [6]\n",
      "All neighbours:  [2, 4, 6, 3]\n",
      "Training node  6\n",
      "Current Node:  7\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [4, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 7.96 MiB / 18.97 MiB   41.94% 00m01s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  2\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [3, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 8.80 MiB / 18.87 MiB   46.63%%00m01s\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  6\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [3, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.95 MiB / 18.95 MiB  100.00%%[2K1s\u001b[2KK[2K\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.91 MiB / 18.91 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.91 MiB / 18.91 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.88 MiB / 18.88 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 0 B / 18.93 MiB    0.00%9.73%%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.96 MiB / 18.96 MiB  100.00%\u001b[2Km11s[2K[2K\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11.87 MiB / 18.97 MiB   62.56%\u001b[2K1s\u001b[2K\u001b[2K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.96 MiB / 18.96 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.53 MiB / 18.96 MiB   97.72%\u001b[2K40ss\r"
     ]
    }
   ],
   "source": [
    "allCl.clients[0].get_nb_weights(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "173037ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allCl.clients[0].personal_accuracy, allCl.clients[1].personal_accuracy, allCl.clients[2].personal_accuracy, allCl.clients[3].personal_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31b6a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  0\n",
      "Untrained Neighbour:  [1, 4, 0]\n",
      "All neighbours:  [1, 4, 0]\n",
      "Training node  1\n",
      "Training node  Training node  0\n",
      "4\n",
      "Current Node:  4\n",
      "Untrained Neighbour:  [3, 7]\n",
      "All neighbours:  [3, 7, 0, 4]\n",
      "Training node  Training node 3 7\n",
      "\n",
      "Current Node:  1\n",
      "Untrained Neighbour:  [5, 2]\n",
      "All neighbours:  [0, 5, 2, 1]\n",
      "Training node  5\n",
      "Training node  2\n",
      "Current Node:  7\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [4, 7]\n",
      "Current Node:  5\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [1, 5]\n",
      "Current Node:  2\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [3, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 3.04 MiB / 18.91 MiB   16.05% 00m06s9s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  3\n",
      "Untrained Neighbour:  [6]\n",
      "All neighbours:  [2, 4, 6, 3]\n",
      "Training node  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1.69 MiB / 18.95 MiB    8.91% 00m14s9s2KK"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Node:  6\n",
      "Untrained Neighbour:  []\n",
      "All neighbours:  [3, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.94 MiB / 18.94 MiB  100.00%%[2K02ss[2K\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.90 MiB / 18.90 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 256.00 KiB / 18.91 MiB    1.32%[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.91 MiB / 18.91 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.96 MiB / 18.96 MiB  100.00%\u001b[2K5s\u001b[2K2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.96 MiB / 18.96 MiB  100.00%\u001b[2K40s[2K\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17.68 MiB / 18.95 MiB   93.27%\u001b[2K2s\u001b[2K2K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.94 MiB / 18.94 MiB  100.00%\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18.59 MiB / 18.93 MiB   98.20%\u001b[2K40s\u001b[2K\r"
     ]
    }
   ],
   "source": [
    "allCl.clients[0].get_nb_weights(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa8417f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.9611904621124268,\n",
       "  1: 0.9576190710067749,\n",
       "  2: 0.9435714483261108,\n",
       "  3: 0.9695237874984741,\n",
       "  4: 0.9480952620506287},\n",
       " {0: 0.9395238161087036,\n",
       "  1: 0.9547619223594666,\n",
       "  2: 0.9680952429771423,\n",
       "  3: 0.9697619080543518,\n",
       "  4: 0.9766666889190674},\n",
       " {0: 0.9616666436195374,\n",
       "  1: 0.9595237970352173,\n",
       "  2: 0.9611904621124268,\n",
       "  3: 0.9690476059913635},\n",
       " {0: 0.9578571319580078,\n",
       "  1: 0.9490476250648499,\n",
       "  2: 0.9607142806053162,\n",
       "  3: 0.9657142758369446})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCl.clients[0].personal_accuracy, allCl.clients[1].personal_accuracy, allCl.clients[2].personal_accuracy, allCl.clients[3].personal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44cafa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allCl.clients[0].get_nb_weights(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b757827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allCl.clients[0].personal_accuracy, allCl.clients[1].personal_accuracy, allCl.clients[2].personal_accuracy, allCl.clients[3].personal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c53b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allCl.clients[0].get_nb_weights(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1bbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
